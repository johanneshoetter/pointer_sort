{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.preprocessing import WordEmbedding, load_word_emb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from utils.metrics import accuracy, precision, recall\n",
    "from models.pointer_net import PointerNet\n",
    "from utils.datasets import SchemaMatchingDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # GPU\n",
    "    'gpu': True,\n",
    "    # Network\n",
    "    'input_size': 300,\n",
    "    'embedding_size': 300,\n",
    "    'hiddens': 256,\n",
    "    'nof_lstms': 2,\n",
    "    'dropout': 0.3,\n",
    "    'bidir': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SchemaMatchingDataset(None, from_path=True)\n",
    "dataset.load('data/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:33<00:00,  3.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:54<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for version in ['sp']: #['sp', 'ap', 'np']:\n",
    "    combined_logs = []\n",
    "    logs_1to0, logs_1to1, logs_1toN = [], [], []\n",
    "    # np = no pretraining\n",
    "    # ap = pretraining on alphabet sorting\n",
    "    # sp = pretraining on 1to1 schema pointing\n",
    "    model = PointerNet(params['input_size'],\n",
    "                       params['embedding_size'],\n",
    "                       params['hiddens'],\n",
    "                       params['nof_lstms'],\n",
    "                       params['dropout'],\n",
    "                       params['bidir'])\n",
    "\n",
    "    model.initialize('serialized/schema_pointer_{}.pt'.format(version))\n",
    "\n",
    "    if params['gpu'] and torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    num_samples = 100\n",
    "    batch_size = 256\n",
    "    for data in tqdm(dataset.yield_bootstrap(num_samples, batch_size), total=num_samples):\n",
    "        try:\n",
    "            inputs, targets = data\n",
    "            if torch.cuda.is_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs, pointers = model(inputs)\n",
    "            acc, rec, prec = accuracy(pointers, targets), recall(pointers, targets), precision(pointers, targets)\n",
    "            log = {\n",
    "                'accuracy': acc,\n",
    "                'recall': rec,\n",
    "                'precision': prec\n",
    "            }\n",
    "            combined_logs.append(log)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for data in tqdm(dataset.yield_bootstrap_by_class(num_samples, batch_size), total=num_samples):\n",
    "        for key in data.keys():\n",
    "            try:\n",
    "                inputs, targets = data[key]\n",
    "                if torch.cuda.is_available:\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                outputs, pointers = model(inputs)\n",
    "                acc, rec, prec = accuracy(pointers, targets), recall(pointers, targets), precision(pointers, targets)\n",
    "                log = {\n",
    "                    'accuracy': acc,\n",
    "                    'recall': rec,\n",
    "                    'precision': prec\n",
    "                }\n",
    "                if key == '1to0':\n",
    "                    logs_1to0.append(log)\n",
    "                elif key == '1to1':\n",
    "                    logs_1to1.append(log)\n",
    "                elif key == '1toN':\n",
    "                    logs_1toN.append(log)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    combined_logs = pd.DataFrame(combined_logs)\n",
    "    combined_logs.to_csv('logging/combined_bootstrap_analysis_batchsize{}_{}.txt'.format(batch_size, version), index=False)\n",
    "    \n",
    "    logs_1to1 = pd.DataFrame(logs_1to1)\n",
    "    logs_1to1.to_csv('logging/o2o_bootstrap_analysis_batchsize{}_{}.txt'.format(batch_size, version), index=False)\n",
    "    \n",
    "    logs_1to0 = pd.DataFrame(logs_1to0)\n",
    "    logs_1to0.to_csv('logging/o2z_bootstrap_analysis_batchsize{}_{}.txt'.format(batch_size, version), index=False)\n",
    "    \n",
    "    logs_1toN = pd.DataFrame(logs_1toN)\n",
    "    logs_1toN.to_csv('logging/o2n_bootstrap_analysis_batchsize{}_{}.txt'.format(batch_size, version), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
