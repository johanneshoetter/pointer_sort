{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortingDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, min_num, max_num, num_samples=10000, size_samples=10):\n",
    "        self.number_pool = [number for number in range(min_num, max_num)]\n",
    "        self.X = torch.Tensor([np.random.choice(self.number_pool, size_samples) for _ in range(num_samples)]).float()\n",
    "        self.Y = torch.Tensor([sorted(numbers) for numbers in self.X]).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.X[idx],\n",
    "            'y': self.Y[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# https://github.com/shirgur/PointerNet #\n",
    "#########################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 n_layers,\n",
    "                 dropout,\n",
    "                 bidir):\n",
    "        \"\"\"\n",
    "        Initiate Encoder\n",
    "        :param Tensor embedding_dim: Number of embbeding channels\n",
    "        :param int hidden_dim: Number of hidden units for the LSTM\n",
    "        :param int n_layers: Number of layers for LSTMs\n",
    "        :param float dropout: Float between 0-1\n",
    "        :param bool bidir: Bidirectional\n",
    "        \"\"\"\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim//2 if bidir else hidden_dim\n",
    "        self.n_layers = n_layers*2 if bidir else n_layers\n",
    "        self.bidir = bidir\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            self.hidden_dim,\n",
    "                            n_layers,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidir)\n",
    "\n",
    "        # Used for propagating .cuda() command\n",
    "        self.h0 = Parameter(torch.zeros(1), requires_grad=False)\n",
    "        self.c0 = Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "    def forward(self, embedded_inputs,\n",
    "                hidden):\n",
    "        \"\"\"\n",
    "        Encoder - Forward-pass\n",
    "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
    "        :param Tensor hidden: Initiated hidden units for the LSTMs (h, c)\n",
    "        :return: LSTMs outputs and hidden units (h, c)\n",
    "        \"\"\"\n",
    "\n",
    "        embedded_inputs = embedded_inputs.permute(1, 0, 2)\n",
    "\n",
    "        outputs, hidden = self.lstm(embedded_inputs, hidden)\n",
    "\n",
    "        return outputs.permute(1, 0, 2), hidden\n",
    "\n",
    "    def init_hidden(self, embedded_inputs):\n",
    "        \"\"\"\n",
    "        Initiate hidden units\n",
    "        :param Tensor embedded_inputs: The embedded input of Pointer-NEt\n",
    "        :return: Initiated hidden units for the LSTMs (h, c)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = embedded_inputs.size(0)\n",
    "\n",
    "        # Reshaping (Expanding)\n",
    "        h0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers,\n",
    "                                                      batch_size,\n",
    "                                                      self.hidden_dim)\n",
    "        c0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers,\n",
    "                                                      batch_size,\n",
    "                                                      self.hidden_dim)\n",
    "\n",
    "        return h0, c0\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention model for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim,\n",
    "                 hidden_dim):\n",
    "        \"\"\"\n",
    "        Initiate Attention\n",
    "        :param int input_dim: Input's diamention\n",
    "        :param int hidden_dim: Number of hidden units in the attention\n",
    "        \"\"\"\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.input_linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.context_linear = nn.Conv1d(input_dim, hidden_dim, 1, 1)\n",
    "        self.V = Parameter(torch.FloatTensor(hidden_dim), requires_grad=True)\n",
    "        self._inf = Parameter(torch.FloatTensor([float('-inf')]), requires_grad=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        # Initialize vector V\n",
    "        nn.init.uniform(self.V, -1, 1)\n",
    "\n",
    "    def forward(self, input,\n",
    "                context,\n",
    "                mask):\n",
    "        \"\"\"\n",
    "        Attention - Forward-pass\n",
    "        :param Tensor input: Hidden state h\n",
    "        :param Tensor context: Attention context\n",
    "        :param ByteTensor mask: Selection mask\n",
    "        :return: tuple of - (Attentioned hidden state, Alphas)\n",
    "        \"\"\"\n",
    "\n",
    "        # (batch, hidden_dim, seq_len)\n",
    "        inp = self.input_linear(input).unsqueeze(2).expand(-1, -1, context.size(1))\n",
    "\n",
    "        # (batch, hidden_dim, seq_len)\n",
    "        context = context.permute(0, 2, 1)\n",
    "        ctx = self.context_linear(context)\n",
    "\n",
    "        # (batch, 1, hidden_dim)\n",
    "        V = self.V.unsqueeze(0).expand(context.size(0), -1).unsqueeze(1)\n",
    "\n",
    "        # (batch, seq_len)\n",
    "        att = torch.bmm(V, self.tanh(inp + ctx)).squeeze(1)\n",
    "        if len(att[mask]) > 0:\n",
    "            att[mask] = self.inf[mask]\n",
    "        alpha = self.softmax(att)\n",
    "\n",
    "        hidden_state = torch.bmm(ctx, alpha.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return hidden_state, alpha\n",
    "\n",
    "    def init_inf(self, mask_size):\n",
    "        self.inf = self._inf.unsqueeze(1).expand(*mask_size)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder model for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,\n",
    "                 hidden_dim):\n",
    "        \"\"\"\n",
    "        Initiate Decoder\n",
    "        :param int embedding_dim: Number of embeddings in Pointer-Net\n",
    "        :param int hidden_dim: Number of hidden units for the decoder's RNN\n",
    "        \"\"\"\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.input_to_hidden = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.hidden_to_hidden = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
    "        self.hidden_out = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.att = Attention(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Used for propagating .cuda() command\n",
    "        self.mask = Parameter(torch.ones(1), requires_grad=False)\n",
    "        self.runner = Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "    def forward(self, embedded_inputs,\n",
    "                decoder_input,\n",
    "                hidden,\n",
    "                context):\n",
    "        \"\"\"\n",
    "        Decoder - Forward-pass\n",
    "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
    "        :param Tensor decoder_input: First decoder's input\n",
    "        :param Tensor hidden: First decoder's hidden states\n",
    "        :param Tensor context: Encoder's outputs\n",
    "        :return: (Output probabilities, Pointers indices), last hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = embedded_inputs.size(0)\n",
    "        input_length = embedded_inputs.size(1)\n",
    "\n",
    "        # (batch, seq_len)\n",
    "        mask = self.mask.repeat(input_length).unsqueeze(0).repeat(batch_size, 1)\n",
    "        self.att.init_inf(mask.size())\n",
    "\n",
    "        # Generating arang(input_length), broadcasted across batch_size\n",
    "        runner = self.runner.repeat(input_length)\n",
    "        for i in range(input_length):\n",
    "            runner.data[i] = i\n",
    "        runner = runner.unsqueeze(0).expand(batch_size, -1).long()\n",
    "\n",
    "        outputs = []\n",
    "        pointers = []\n",
    "\n",
    "        def step(x, hidden):\n",
    "            \"\"\"\n",
    "            Recurrence step function\n",
    "            :param Tensor x: Input at time t\n",
    "            :param tuple(Tensor, Tensor) hidden: Hidden states at time t-1\n",
    "            :return: Hidden states at time t (h, c), Attention probabilities (Alpha)\n",
    "            \"\"\"\n",
    "\n",
    "            # Regular LSTM\n",
    "            h, c = hidden\n",
    "\n",
    "            gates = self.input_to_hidden(x) + self.hidden_to_hidden(h)\n",
    "            input, forget, cell, out = gates.chunk(4, 1)\n",
    "\n",
    "            input = F.sigmoid(input)\n",
    "            forget = F.sigmoid(forget)\n",
    "            cell = F.tanh(cell)\n",
    "            out = F.sigmoid(out)\n",
    "\n",
    "            c_t = (forget * c) + (input * cell)\n",
    "            h_t = out * F.tanh(c_t)\n",
    "\n",
    "            # Attention section\n",
    "            hidden_t, output = self.att(h_t, context, torch.eq(mask, 0))\n",
    "            hidden_t = F.tanh(self.hidden_out(torch.cat((hidden_t, h_t), 1)))\n",
    "\n",
    "            return hidden_t, c_t, output\n",
    "\n",
    "        # Recurrence loop\n",
    "        for _ in range(input_length):\n",
    "            h_t, c_t, outs = step(decoder_input, hidden)\n",
    "            hidden = (h_t, c_t)\n",
    "\n",
    "            # Masking selected inputs\n",
    "            masked_outs = outs * mask\n",
    "\n",
    "            # Get maximum probabilities and indices\n",
    "            max_probs, indices = masked_outs.max(1)\n",
    "            one_hot_pointers = (runner == indices.unsqueeze(1).expand(-1, outs.size()[1])).float()\n",
    "\n",
    "            # Update mask to ignore seen indices\n",
    "            mask  = mask * (1 - one_hot_pointers)\n",
    "\n",
    "            # Get embedded inputs by max indices\n",
    "            embedding_mask = one_hot_pointers.unsqueeze(2).expand(-1, -1, self.embedding_dim).byte()\n",
    "            decoder_input = embedded_inputs[embedding_mask.data].view(batch_size, self.embedding_dim)\n",
    "\n",
    "            outputs.append(outs.unsqueeze(0))\n",
    "            pointers.append(indices.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs).permute(1, 0, 2)\n",
    "        pointers = torch.cat(pointers, 1)\n",
    "\n",
    "        return (outputs, pointers), hidden\n",
    "\n",
    "\n",
    "class PointerNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 lstm_layers,\n",
    "                 dropout,\n",
    "                 bidir=False):\n",
    "        \"\"\"\n",
    "        Initiate Pointer-Net\n",
    "        :param int embedding_dim: Number of embbeding channels\n",
    "        :param int hidden_dim: Encoders hidden units\n",
    "        :param int lstm_layers: Number of layers for LSTMs\n",
    "        :param float dropout: Float between 0-1\n",
    "        :param bool bidir: Bidirectional\n",
    "        \"\"\"\n",
    "\n",
    "        super(PointerNet, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.bidir = bidir\n",
    "        self.embedding = nn.Linear(1, embedding_dim) #nn.Linear(2, embedding_dim)\n",
    "        self.encoder = Encoder(embedding_dim,\n",
    "                               hidden_dim,\n",
    "                               lstm_layers,\n",
    "                               dropout,\n",
    "                               bidir)\n",
    "        self.decoder = Decoder(embedding_dim, hidden_dim)\n",
    "        self.decoder_input0 = Parameter(torch.FloatTensor(embedding_dim), requires_grad=False)\n",
    "\n",
    "        # Initialize decoder_input0\n",
    "        nn.init.uniform(self.decoder_input0, -1, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        PointerNet - Forward-pass\n",
    "        :param Tensor inputs: Input sequence\n",
    "        :return: Pointers probabilities and indices\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        input_length = inputs.size(1)\n",
    "\n",
    "        decoder_input0 = self.decoder_input0.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        inputs = inputs.view(batch_size * input_length, -1)\n",
    "        embedded_inputs = self.embedding(inputs).view(batch_size, input_length, -1)\n",
    "\n",
    "        encoder_hidden0 = self.encoder.init_hidden(embedded_inputs)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(embedded_inputs,\n",
    "                                                       encoder_hidden0)\n",
    "        if self.bidir:\n",
    "            decoder_hidden0 = (torch.cat(encoder_hidden[0][-2:], dim=-1),\n",
    "                               torch.cat(encoder_hidden[1][-2:], dim=-1))\n",
    "        else:\n",
    "            decoder_hidden0 = (encoder_hidden[0][-1],\n",
    "                               encoder_hidden[1][-1])\n",
    "        (outputs, pointers), decoder_hidden = self.decoder(embedded_inputs,\n",
    "                                                           decoder_input0,\n",
    "                                                           decoder_hidden0,\n",
    "                                                           encoder_outputs)\n",
    "\n",
    "        return  outputs, pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Data\n",
    "    'batch_size': 1,\n",
    "    'shuffle': True,\n",
    "    'nof_workers': 0, # must stay at 0\n",
    "    #Train\n",
    "    'nof_epoch': 30,\n",
    "    'lr': 0.01,\n",
    "    # GPU\n",
    "    'gpu': True,\n",
    "    # Network\n",
    "    'embedding_size': 10,\n",
    "    'hiddens': 256,\n",
    "    'nof_lstms': 2,\n",
    "    'dropout': 0.3,\n",
    "    'bidir': False # True not working right now\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU, 1 devices.\n"
     ]
    }
   ],
   "source": [
    "if params['gpu'] and torch.cuda.is_available():\n",
    "    USE_CUDA = True\n",
    "    print('Using GPU, %i devices.' % torch.cuda.device_count())\n",
    "else:\n",
    "    USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(params['embedding_size'],\n",
    "                   params['hiddens'],\n",
    "                   params['nof_lstms'],\n",
    "                   params['dropout'],\n",
    "                   params['bidir'])\n",
    "\n",
    "dataset = SortingDataset(0, 10)\n",
    "\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        shuffle=params['shuffle'],\n",
    "                        num_workers=params['nof_workers'])\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    net = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "CCE = torch.nn.CrossEntropyLoss()\n",
    "model_optim = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                model.parameters()),\n",
    "                                 lr=params['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                     | 0/10000 [00:00<?, ?Batch/s]\u001b[A\n",
      "Epoch 1/30:   0%|                                                                         | 0/10000 [00:00<?, ?Batch/s]\u001b[A\n",
      "Epoch 1/30:   0%|                                                | 0/10000 [00:00<?, ?Batch/s, loss=2.1164064407348633]\u001b[A"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(params['nof_epoch']):\n",
    "    batch_loss = []\n",
    "    iterator = tqdm(dataloader, unit='Batch')\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(iterator):\n",
    "        iterator.set_description('Epoch %i/%i' % (epoch+1, params['nof_epoch']))\n",
    "\n",
    "        train_batch = Variable(sample_batched['x'])\n",
    "        target_batch = Variable(sample_batched['y'])\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            train_batch = train_batch.cuda()\n",
    "            target_batch = target_batch.cuda()\n",
    "\n",
    "        o, p = model(train_batch)\n",
    "        \n",
    "        #o = o.contiguous().view(-1, o.size()[-1])\n",
    "        #target_batch = target_batch.view(-1)\n",
    "        \n",
    "        loss = F.cross_entropy(o, target_batch) #/ target_batch.shape[1] # need to take the length of the table into account\n",
    "        #acc = get_accuracy(p, target_batch)\n",
    "        \n",
    "        losses.append(loss.data)\n",
    "        batch_loss.append(loss.data)\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        \n",
    "        iterator.set_postfix(loss='{}'.format(loss.data))\n",
    "        break\n",
    "    break\n",
    "    batch_loss = torch.Tensor(batch_loss)\n",
    "    iterator.set_postfix(loss=np.average(batch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9962e-01, 2.1050e-04, 4.2210e-05, 1.7600e-05, 1.9683e-05,\n",
       "          1.9611e-05, 2.0233e-05, 1.8876e-05, 1.6975e-05, 1.1053e-05],\n",
       "         [0.0000e+00, 1.2585e-01, 1.1394e-01, 1.0813e-01, 1.0924e-01,\n",
       "          1.0926e-01, 1.0979e-01, 1.0994e-01, 1.0841e-01, 1.0543e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 1.2601e-01, 1.2479e-01, 1.2499e-01,\n",
       "          1.2500e-01, 1.2511e-01, 1.2514e-01, 1.2479e-01, 1.2416e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4282e-01, 1.4296e-01,\n",
       "          1.4297e-01, 1.4305e-01, 1.4307e-01, 1.4280e-01, 1.4233e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6667e-01, 1.6681e-01,\n",
       "          1.6682e-01, 1.6690e-01, 0.0000e+00, 1.6664e-01, 1.6616e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0006e-01, 2.0019e-01,\n",
       "          2.0019e-01, 0.0000e+00, 0.0000e+00, 2.0001e-01, 1.9955e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5013e-01, 2.5026e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5006e-01, 2.4955e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3361e-01, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3352e-01, 3.3288e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0045e-01, 4.9955e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 7, 6, 5, 4, 3, 8, 9]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 2, 4, 5, 6, 6, 8, 8, 9]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
