{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] -- Train\n",
      "OUT SHAPE torch.Size([32, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "HS SHAPE  torch.Size([1, 32, 256]) torch.Size([1, 32, 256])\n",
      "0\n",
      "DEC IN SHAPE 2:  torch.Size([32])\n",
      "1\n",
      "DEC IN SHAPE 2:  torch.Size([32])\n",
      "2\n",
      "DEC IN SHAPE 2:  torch.Size([32])\n",
      "3\n",
      "DEC IN SHAPE 2:  torch.Size([32])\n",
      "Epoch [1] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "HS SHAPE  torch.Size([1, 4, 256]) torch.Size([1, 4, 256])\n",
      "0\n",
      "DEC IN SHAPE 2:  torch.Size([4])\n",
      "1\n",
      "DEC IN SHAPE 2:  torch.Size([4])\n",
      "2\n",
      "DEC IN SHAPE 2:  torch.Size([4])\n",
      "3\n",
      "DEC IN SHAPE 2:  torch.Size([4])\n",
      "tensor([4, 5, 0, 3]) --> tensor([5, 5, 5, 5]) --> tensor([0, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Module implementing the pointer network proposed at: https://arxiv.org/abs/1506.03134\n",
    "The implementation try to follows the variables naming conventions\n",
    "ei: Encoder hidden state\n",
    "di: Decoder hidden state\n",
    "di_prime: Attention aware decoder state\n",
    "W1: Learnable matrix (Attention layer)\n",
    "W2: Learnable matrix (Attention layer)\n",
    "V: Learnable parameter (Attention layer)\n",
    "uj: Energy vector (Attention Layer)\n",
    "aj: Attention mask over the input\n",
    "\"\"\"\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import batch\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 500\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (BATCH, ARRAY_LEN, 1)\n",
    "        return self.lstm(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = nn.Linear(hidden_size, units, bias=False)\n",
    "        self.W2 = nn.Linear(hidden_size, units, bias=False)\n",
    "        self.V =  nn.Linear(units, 1, bias=False)\n",
    "\n",
    "    def forward(self, \n",
    "                  encoder_out: torch.Tensor, \n",
    "                  decoder_hidden: torch.Tensor):\n",
    "        # encoder_out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # decoder_hidden: (BATCH, HIDDEN_SIZE)\n",
    "\n",
    "        # Add time axis to decoder hidden state\n",
    "        # in order to make operations compatible with encoder_out\n",
    "        # decoder_hidden_time: (BATCH, 1, HIDDEN_SIZE)\n",
    "        decoder_hidden_time = decoder_hidden.unsqueeze(1)\n",
    "\n",
    "        # uj: (BATCH, ARRAY_LEN, ATTENTION_UNITS)\n",
    "        # Note: we can add the both linear outputs thanks to broadcasting\n",
    "        uj = self.W1(encoder_out) + self.W2(decoder_hidden_time)\n",
    "        uj = torch.tanh(uj)\n",
    "\n",
    "        # uj: (BATCH, ARRAY_LEN, 1)\n",
    "        uj = self.V(uj)\n",
    "\n",
    "        # Attention mask over inputs\n",
    "        # aj: (BATCH, ARRAY_LEN, 1)\n",
    "        aj = F.softmax(uj, dim=1)\n",
    "\n",
    "        # di_prime: (BATCH, HIDDEN_SIZE)\n",
    "        di_prime = aj * encoder_out\n",
    "        di_prime = di_prime.sum(1)\n",
    "\n",
    "        return di_prime, uj.squeeze(-1)\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "               hidden_size: int,\n",
    "               attention_units: int = 10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(hidden_size + 1, hidden_size, batch_first=True)\n",
    "        self.attention = Attention(hidden_size, attention_units)\n",
    "\n",
    "    def forward(self, \n",
    "                  x: torch.Tensor, \n",
    "                  hidden: Tuple[torch.Tensor], \n",
    "                  encoder_out: torch.Tensor):\n",
    "        # x: (BATCH, 1, 1) \n",
    "        # hidden: (1, BATCH, HIDDEN_SIZE)\n",
    "        # encoder_out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # For a better understanding about hidden shapes read: https://pytorch.org/docs/stable/nn.html#lstm\n",
    "\n",
    "        # Get hidden states (not cell states) \n",
    "        # from the first and unique LSTM layer \n",
    "        ht = hidden[0][0]  # ht: (BATCH, HIDDEN_SIZE)\n",
    "\n",
    "        # di: Attention aware hidden state -> (BATCH, HIDDEN_SIZE)\n",
    "        # att_w: Not 'softmaxed', torch will take care of it -> (BATCH, ARRAY_LEN)\n",
    "        di, att_w = self.attention(encoder_out, ht)\n",
    "\n",
    "        # Append attention aware hidden state to our input\n",
    "        # x: (BATCH, 1, 1 + HIDDEN_SIZE)\n",
    "        x = torch.cat([di.unsqueeze(1), x], dim=2)\n",
    "\n",
    "        # Generate the hidden state for next timestep\n",
    "        _, hidden = self.lstm(x, hidden)\n",
    "        return hidden, att_w\n",
    "\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "                   encoder: nn.Module, \n",
    "                   decoder: nn.Module):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, \n",
    "                  x: torch.Tensor, \n",
    "                  y: torch.Tensor, \n",
    "                  teacher_force_ratio=.5):\n",
    "        # x: (BATCH_SIZE, ARRAY_LEN)\n",
    "        # y: (BATCH_SIZE, ARRAY_LEN)\n",
    "\n",
    "        # Array elements as features\n",
    "        # encoder_in: (BATCH, ARRAY_LEN, 1)\n",
    "        encoder_in = x.unsqueeze(-1).type(torch.float)\n",
    "        \n",
    "        # out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # hs: tuple of (NUM_LAYERS, BATCH, HIDDEN_SIZE)\n",
    "        out, hs = encoder(encoder_in)\n",
    "\n",
    "        # Accum loss throughout timesteps\n",
    "        loss = 0\n",
    "\n",
    "        # Save outputs at each timestep\n",
    "        # outputs: (ARRAY_LEN, BATCH)\n",
    "        outputs = torch.zeros(out.size(1), out.size(0), dtype=torch.long)\n",
    "\n",
    "        # First decoder input is always 0\n",
    "        # dec_in: (BATCH, 1, 1)\n",
    "        dec_in = torch.zeros(out.size(0), 1, 1, dtype=torch.float)\n",
    "\n",
    "        print(\"OUT SHAPE\", out.shape)\n",
    "        print(\"OUTPUTS SHAPE \", outputs.shape)\n",
    "        print(\"DEC IN SHAPE \", dec_in.shape)\n",
    "        print(\"HS SHAPE \", hs[0].shape, hs[1].shape)\n",
    "        \n",
    "        for t in range(out.size(1)):\n",
    "            print(t)\n",
    "            hs, att_w = decoder(dec_in, hs, out)\n",
    "            predictions = F.softmax(att_w, dim=1).argmax(1)\n",
    "\n",
    "            # Pick next index\n",
    "            # If teacher force the next element will we the ground truth\n",
    "            # otherwise will be the predicted value at current timestep\n",
    "            teacher_force = random.random() < teacher_force_ratio\n",
    "            idx = y[:, t] if teacher_force else predictions\n",
    "            dec_in = torch.stack([x[b, idx[b].item()] for b in range(x.size(0))])\n",
    "            print(\"DEC IN SHAPE 2: \", dec_in.shape)\n",
    "            dec_in = dec_in.view(out.size(0), 1, 1).type(torch.float)\n",
    "\n",
    "            # Add cross entropy loss (F.log_softmax + nll_loss)\n",
    "            loss += F.cross_entropy(att_w, y[:, t])\n",
    "            outputs[t] = predictions\n",
    "\n",
    "        # Weight losses, so every element in the batch \n",
    "        # has the same 'importance' \n",
    "        batch_loss = loss / y.size(0)\n",
    "\n",
    "        return outputs, batch_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, clip=1.):\n",
    "    \"\"\"Train single epoch\"\"\"\n",
    "    print('Epoch [{}] -- Train'.format(epoch))\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        x, y = batch(BATCH_SIZE)\n",
    "        out, loss = model(x, y)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        break\n",
    "\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print('Epoch [{}] loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, epoch):\n",
    "    \"\"\"Evaluate after a train epoch\"\"\"\n",
    "    print('Epoch [{}] -- Evaluate'.format(epoch))\n",
    "\n",
    "    x_val, y_val = batch(4)\n",
    "\n",
    "    out, _ = model(x_val, y_val, teacher_force_ratio=0.)\n",
    "    out = out.permute(1, 0)\n",
    "\n",
    "    for i in range(out.size(0)):\n",
    "        print('{} --> {} --> {}'.format(\n",
    "          x_val[i], \n",
    "          x_val[i].gather(0, out[i]), \n",
    "          x_val[i].gather(0, y_val[i])\n",
    "        ))\n",
    "        break\n",
    "\n",
    "\n",
    "encoder = Encoder(HIDDEN_SIZE)\n",
    "decoder = Decoder(HIDDEN_SIZE)\n",
    "ptr_net = PointerNetwork(encoder, decoder)\n",
    "\n",
    "optimizer = optim.Adam(ptr_net.parameters())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(ptr_net, optimizer, epoch + 1)\n",
    "    evaluate(ptr_net, epoch + 1)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
