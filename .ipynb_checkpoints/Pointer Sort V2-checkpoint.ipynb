{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] -- Train\n",
      "OUT SHAPE torch.Size([32, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [1] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([5, 9, 9, 5, 3, 9, 0, 8]) --> tensor([5, 5, 5, 5, 5, 5, 5, 5]) --> tensor([0, 3, 5, 5, 8, 9, 9, 9])\n",
      "tensor([4, 3, 4, 2, 1, 1, 7, 2]) --> tensor([4, 4, 4, 4, 4, 4, 4, 4]) --> tensor([1, 1, 2, 2, 3, 4, 4, 7])\n",
      "tensor([4, 6, 7, 8, 2, 2, 2, 2]) --> tensor([4, 4, 4, 4, 4, 4, 4, 4]) --> tensor([2, 2, 2, 2, 4, 6, 7, 8])\n",
      "tensor([5, 3, 0, 2, 1, 2, 3, 1]) --> tensor([5, 5, 5, 5, 5, 5, 5, 5]) --> tensor([0, 1, 1, 2, 2, 3, 3, 5])\n",
      "Epoch [2] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [2] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([7, 3, 0, 8, 1, 7, 5, 6]) --> tensor([0, 1, 1, 1, 1, 1, 1, 1]) --> tensor([0, 1, 3, 5, 6, 7, 7, 8])\n",
      "tensor([9, 1, 6, 0, 6, 9, 6, 5]) --> tensor([1, 1, 1, 1, 6, 6, 6, 6]) --> tensor([0, 1, 5, 6, 6, 6, 9, 9])\n",
      "tensor([8, 4, 3, 9, 4, 3, 2, 6]) --> tensor([4, 4, 4, 4, 4, 4, 4, 4]) --> tensor([2, 3, 3, 4, 4, 6, 8, 9])\n",
      "tensor([9, 7, 3, 5, 9, 0, 1, 8]) --> tensor([0, 0, 0, 0, 0, 0, 0, 0]) --> tensor([0, 1, 3, 5, 7, 8, 9, 9])\n",
      "Epoch [3] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [3] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([6, 0, 3, 9, 9, 3, 5, 7, 3, 0]) --> tensor([0, 0, 3, 3, 3, 3, 7, 7, 7, 7]) --> tensor([0, 0, 3, 3, 3, 5, 6, 7, 9, 9])\n",
      "tensor([9, 7, 7, 0, 2, 2, 6, 2, 8, 7]) --> tensor([0, 0, 0, 0, 0, 7, 7, 7, 7, 7]) --> tensor([0, 2, 2, 2, 6, 7, 7, 7, 8, 9])\n",
      "tensor([3, 3, 6, 5, 3, 6, 8, 1, 3, 7]) --> tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) --> tensor([1, 3, 3, 3, 3, 5, 6, 6, 7, 8])\n",
      "tensor([9, 8, 3, 7, 0, 8, 7, 5, 2, 9]) --> tensor([0, 0, 2, 2, 5, 5, 5, 5, 5, 5]) --> tensor([0, 2, 3, 5, 7, 7, 8, 8, 9, 9])\n",
      "Epoch [4] -- Train\n",
      "OUT SHAPE torch.Size([32, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [4] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([1, 2, 5, 4, 5, 8, 7, 3, 7, 5]) --> tensor([2, 3, 3, 5, 5, 5, 5, 7, 7, 7]) --> tensor([1, 2, 3, 4, 5, 5, 5, 7, 7, 8])\n",
      "tensor([3, 1, 6, 4, 3, 4, 7, 6, 8, 8]) --> tensor([1, 1, 3, 8, 8, 8, 8, 8, 8, 8]) --> tensor([1, 3, 3, 4, 4, 6, 6, 7, 8, 8])\n",
      "tensor([0, 5, 3, 9, 9, 2, 1, 7, 4, 4]) --> tensor([1, 1, 2, 2, 2, 2, 2, 2, 9, 9]) --> tensor([0, 1, 2, 3, 4, 4, 5, 7, 9, 9])\n",
      "tensor([8, 3, 5, 8, 5, 6, 7, 5, 3, 7]) --> tensor([3, 3, 3, 5, 5, 5, 7, 7, 7, 7]) --> tensor([3, 3, 5, 5, 5, 6, 7, 7, 8, 8])\n",
      "Epoch [5] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [5] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 9, 256])\n",
      "OUTPUTS SHAPE  torch.Size([9, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([0, 5, 4, 1, 0, 5, 9, 2, 0]) --> tensor([0, 0, 0, 2, 2, 2, 2, 2, 2]) --> tensor([0, 0, 0, 1, 2, 4, 5, 5, 9])\n",
      "tensor([4, 6, 7, 4, 9, 7, 2, 7, 2]) --> tensor([4, 2, 2, 7, 7, 7, 7, 7, 7]) --> tensor([2, 2, 4, 4, 6, 7, 7, 7, 9])\n",
      "tensor([3, 6, 0, 3, 8, 8, 0, 5, 7]) --> tensor([0, 0, 0, 0, 0, 7, 8, 8, 8]) --> tensor([0, 0, 3, 3, 5, 6, 7, 8, 8])\n",
      "tensor([6, 4, 6, 9, 8, 1, 0, 8, 3]) --> tensor([0, 0, 1, 1, 8, 8, 8, 8, 8]) --> tensor([0, 1, 3, 4, 6, 6, 8, 8, 9])\n",
      "Epoch [6] -- Train\n",
      "OUT SHAPE torch.Size([32, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [6] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 3, 256])\n",
      "OUTPUTS SHAPE  torch.Size([3, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([8, 6, 4]) --> tensor([8, 4, 4]) --> tensor([4, 6, 8])\n",
      "tensor([7, 8, 9]) --> tensor([7, 7, 9]) --> tensor([7, 8, 9])\n",
      "tensor([0, 1, 9]) --> tensor([1, 1, 1]) --> tensor([0, 1, 9])\n",
      "tensor([5, 0, 7]) --> tensor([0, 0, 0]) --> tensor([0, 5, 7])\n",
      "Epoch [7] -- Train\n",
      "OUT SHAPE torch.Size([32, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [7] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([1, 9, 9, 0, 1, 7, 8, 0, 9, 9]) --> tensor([1, 1, 1, 9, 9, 9, 9, 9, 9, 9]) --> tensor([0, 0, 1, 1, 7, 8, 9, 9, 9, 9])\n",
      "tensor([4, 5, 8, 1, 8, 8, 3, 8, 0, 1]) --> tensor([4, 4, 8, 8, 8, 8, 8, 8, 8, 8]) --> tensor([0, 1, 1, 3, 4, 5, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 4, 3, 7, 2, 9, 7]) --> tensor([8, 8, 7, 7, 7, 7, 7, 7, 7, 7]) --> tensor([2, 3, 4, 7, 7, 8, 8, 8, 8, 9])\n",
      "tensor([3, 3, 3, 2, 6, 4, 0, 9, 2, 1]) --> tensor([3, 0, 2, 2, 9, 9, 9, 9, 9, 9]) --> tensor([0, 1, 2, 2, 3, 3, 3, 4, 6, 9])\n",
      "Epoch [8] -- Train\n",
      "OUT SHAPE torch.Size([32, 9, 256])\n",
      "OUTPUTS SHAPE  torch.Size([9, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [8] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([4, 7, 1, 0, 4, 7, 8]) --> tensor([0, 0, 0, 8, 8, 8, 8]) --> tensor([0, 1, 4, 4, 7, 7, 8])\n",
      "tensor([8, 7, 4, 5, 5, 7, 9]) --> tensor([8, 8, 9, 9, 9, 9, 9]) --> tensor([4, 5, 5, 7, 7, 8, 9])\n",
      "tensor([0, 2, 8, 3, 3, 9, 0]) --> tensor([0, 0, 0, 0, 9, 9, 9]) --> tensor([0, 0, 2, 3, 3, 8, 9])\n",
      "tensor([6, 5, 4, 4, 4, 9, 0]) --> tensor([6, 6, 0, 9, 9, 9, 9]) --> tensor([0, 4, 4, 4, 5, 6, 9])\n",
      "Epoch [9] -- Train\n",
      "OUT SHAPE torch.Size([32, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [9] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([6, 0, 5, 1, 2, 4, 4]) --> tensor([0, 0, 1, 4, 4, 4, 4]) --> tensor([0, 1, 2, 4, 4, 5, 6])\n",
      "tensor([2, 0, 4, 3, 7, 0, 7]) --> tensor([0, 0, 0, 7, 7, 7, 7]) --> tensor([0, 0, 2, 3, 4, 7, 7])\n",
      "tensor([4, 9, 5, 1, 1, 5, 2]) --> tensor([1, 1, 1, 5, 5, 5, 5]) --> tensor([1, 1, 2, 4, 5, 5, 9])\n",
      "tensor([9, 6, 7, 6, 6, 7, 9]) --> tensor([9, 9, 9, 9, 9, 9, 9]) --> tensor([6, 6, 6, 7, 7, 9, 9])\n",
      "Epoch [10] -- Train\n",
      "OUT SHAPE torch.Size([32, 3, 256])\n",
      "OUTPUTS SHAPE  torch.Size([3, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [10] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([1, 6, 5, 8]) --> tensor([1, 1, 8, 8]) --> tensor([1, 5, 6, 8])\n",
      "tensor([9, 5, 0, 8]) --> tensor([0, 0, 0, 8]) --> tensor([0, 5, 8, 9])\n",
      "tensor([9, 0, 7, 9]) --> tensor([0, 0, 9, 9]) --> tensor([0, 7, 9, 9])\n",
      "tensor([4, 1, 4, 2]) --> tensor([1, 1, 2, 2]) --> tensor([1, 2, 4, 4])\n",
      "Epoch [11] -- Train\n",
      "OUT SHAPE torch.Size([32, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [11] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 5, 256])\n",
      "OUTPUTS SHAPE  torch.Size([5, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([3, 2, 1, 7, 2]) --> tensor([1, 1, 2, 2, 7]) --> tensor([1, 2, 2, 3, 7])\n",
      "tensor([1, 2, 8, 4, 0]) --> tensor([1, 0, 0, 4, 4]) --> tensor([0, 1, 2, 4, 8])\n",
      "tensor([6, 3, 2, 0, 6]) --> tensor([0, 0, 0, 6, 6]) --> tensor([0, 2, 3, 6, 6])\n",
      "tensor([5, 5, 8, 6, 4]) --> tensor([5, 5, 4, 6, 6]) --> tensor([4, 5, 5, 6, 8])\n",
      "Epoch [12] -- Train\n",
      "OUT SHAPE torch.Size([32, 9, 256])\n",
      "OUTPUTS SHAPE  torch.Size([9, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [12] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([2, 9, 8, 5, 0, 5, 5, 7]) --> tensor([2, 2, 0, 7, 7, 7, 7, 7]) --> tensor([0, 2, 5, 5, 5, 7, 8, 9])\n",
      "tensor([6, 5, 7, 7, 9, 4, 7, 8]) --> tensor([6, 6, 4, 8, 8, 8, 8, 8]) --> tensor([4, 5, 6, 7, 7, 7, 8, 9])\n",
      "tensor([3, 5, 9, 8, 1, 0, 4, 7]) --> tensor([0, 0, 0, 8, 8, 8, 8, 8]) --> tensor([0, 1, 3, 4, 5, 7, 8, 9])\n",
      "tensor([5, 4, 4, 0, 2, 7, 8, 7]) --> tensor([0, 0, 0, 7, 7, 7, 7, 7]) --> tensor([0, 2, 4, 4, 5, 7, 7, 8])\n",
      "Epoch [13] -- Train\n",
      "OUT SHAPE torch.Size([32, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [13] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([1, 8, 8, 3, 3, 9, 6, 3]) --> tensor([1, 1, 1, 6, 6, 6, 6, 6]) --> tensor([1, 3, 3, 3, 6, 8, 8, 9])\n",
      "tensor([4, 7, 6, 6, 2, 5, 5, 1]) --> tensor([4, 1, 1, 5, 6, 5, 5, 5]) --> tensor([1, 2, 4, 5, 5, 6, 6, 7])\n",
      "tensor([5, 4, 0, 8, 8, 3, 8, 9]) --> tensor([0, 0, 0, 9, 9, 9, 9, 9]) --> tensor([0, 3, 4, 5, 8, 8, 8, 9])\n",
      "tensor([2, 0, 5, 6, 6, 4, 1, 9]) --> tensor([0, 0, 1, 9, 9, 9, 9, 9]) --> tensor([0, 1, 2, 4, 5, 6, 6, 9])\n",
      "Epoch [14] -- Train\n",
      "OUT SHAPE torch.Size([32, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [14] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 3, 256])\n",
      "OUTPUTS SHAPE  torch.Size([3, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([4, 2, 8]) --> tensor([2, 2, 8]) --> tensor([2, 4, 8])\n",
      "tensor([4, 6, 4]) --> tensor([4, 4, 4]) --> tensor([4, 4, 6])\n",
      "tensor([8, 3, 5]) --> tensor([3, 3, 5]) --> tensor([3, 5, 8])\n",
      "tensor([0, 1, 2]) --> tensor([1, 2, 2]) --> tensor([0, 1, 2])\n",
      "Epoch [15] -- Train\n",
      "OUT SHAPE torch.Size([32, 5, 256])\n",
      "OUTPUTS SHAPE  torch.Size([5, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [15] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 5, 256])\n",
      "OUTPUTS SHAPE  torch.Size([5, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([9, 1, 1, 2, 3]) --> tensor([1, 1, 1, 3, 9]) --> tensor([1, 1, 2, 3, 9])\n",
      "tensor([3, 3, 9, 5, 0]) --> tensor([0, 0, 0, 5, 5]) --> tensor([0, 3, 3, 5, 9])\n",
      "tensor([5, 5, 4, 2, 6]) --> tensor([2, 2, 2, 6, 6]) --> tensor([2, 4, 5, 5, 6])\n",
      "tensor([8, 9, 2, 1, 1]) --> tensor([1, 1, 1, 9, 9]) --> tensor([1, 1, 2, 8, 9])\n",
      "Epoch [16] -- Train\n",
      "OUT SHAPE torch.Size([32, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([5, 9, 9, 0, 4, 3, 9, 3]) --> tensor([0, 0, 0, 9, 9, 9, 9, 9]) --> tensor([0, 3, 3, 4, 5, 9, 9, 9])\n",
      "tensor([3, 0, 2, 3, 0, 9, 8, 9]) --> tensor([0, 0, 0, 9, 9, 9, 9, 9]) --> tensor([0, 0, 2, 3, 3, 8, 9, 9])\n",
      "tensor([3, 1, 3, 9, 3, 2, 1, 3]) --> tensor([1, 1, 1, 9, 9, 9, 9, 9]) --> tensor([1, 1, 2, 3, 3, 3, 3, 9])\n",
      "tensor([9, 0, 0, 0, 1, 1, 3, 8]) --> tensor([0, 0, 0, 8, 8, 8, 8, 8]) --> tensor([0, 0, 0, 1, 1, 3, 8, 9])\n",
      "Epoch [17] -- Train\n",
      "OUT SHAPE torch.Size([32, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [17] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 4, 256])\n",
      "OUTPUTS SHAPE  torch.Size([4, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([3, 2, 5, 3]) --> tensor([2, 2, 3, 3]) --> tensor([2, 3, 3, 5])\n",
      "tensor([5, 2, 4, 6]) --> tensor([2, 2, 6, 6]) --> tensor([2, 4, 5, 6])\n",
      "tensor([5, 2, 9, 2]) --> tensor([2, 2, 2, 9]) --> tensor([2, 2, 5, 9])\n",
      "tensor([0, 8, 7, 9]) --> tensor([0, 0, 0, 9]) --> tensor([0, 7, 8, 9])\n",
      "Epoch [18] -- Train\n",
      "OUT SHAPE torch.Size([32, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [18] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 5, 256])\n",
      "OUTPUTS SHAPE  torch.Size([5, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([7, 8, 5, 3, 2]) --> tensor([2, 2, 2, 8, 8]) --> tensor([2, 3, 5, 7, 8])\n",
      "tensor([0, 6, 6, 9, 8]) --> tensor([0, 0, 0, 8, 8]) --> tensor([0, 6, 6, 8, 9])\n",
      "tensor([2, 5, 6, 4, 0]) --> tensor([0, 0, 0, 4, 6]) --> tensor([0, 2, 4, 5, 6])\n",
      "tensor([4, 9, 5, 7, 4]) --> tensor([4, 4, 4, 7, 7]) --> tensor([4, 4, 5, 7, 9])\n",
      "Epoch [19] -- Train\n",
      "OUT SHAPE torch.Size([32, 3, 256])\n",
      "OUTPUTS SHAPE  torch.Size([3, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [19] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 3, 256])\n",
      "OUTPUTS SHAPE  torch.Size([3, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([2, 4, 6]) --> tensor([2, 2, 6]) --> tensor([2, 4, 6])\n",
      "tensor([2, 2, 3]) --> tensor([2, 2, 3]) --> tensor([2, 2, 3])\n",
      "tensor([2, 6, 8]) --> tensor([2, 2, 8]) --> tensor([2, 6, 8])\n",
      "tensor([6, 0, 4]) --> tensor([0, 0, 4]) --> tensor([0, 4, 6])\n",
      "Epoch [20] -- Train\n",
      "OUT SHAPE torch.Size([32, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [20] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([3, 5, 9, 8, 4, 5, 8]) --> tensor([3, 3, 3, 3, 8, 8, 8]) --> tensor([3, 4, 5, 5, 8, 8, 9])\n",
      "tensor([4, 2, 1, 6, 5, 6, 1]) --> tensor([1, 1, 1, 1, 6, 6, 6]) --> tensor([1, 1, 2, 4, 5, 6, 6])\n",
      "tensor([3, 2, 0, 4, 4, 7, 0]) --> tensor([0, 0, 0, 0, 7, 7, 7]) --> tensor([0, 0, 2, 3, 4, 4, 7])\n",
      "tensor([6, 1, 5, 5, 5, 1, 9]) --> tensor([1, 1, 1, 1, 9, 9, 9]) --> tensor([1, 1, 5, 5, 5, 6, 9])\n",
      "Epoch [21] -- Train\n",
      "OUT SHAPE torch.Size([32, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [21] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([7, 2, 9, 0, 4, 1]) --> tensor([0, 0, 0, 0, 9, 9]) --> tensor([0, 1, 2, 4, 7, 9])\n",
      "tensor([8, 9, 3, 1, 5, 0]) --> tensor([0, 0, 0, 0, 9, 9]) --> tensor([0, 1, 3, 5, 8, 9])\n",
      "tensor([5, 0, 5, 3, 6, 6]) --> tensor([0, 0, 0, 0, 6, 6]) --> tensor([0, 3, 5, 5, 6, 6])\n",
      "tensor([9, 8, 4, 3, 4, 5]) --> tensor([3, 3, 3, 3, 8, 8]) --> tensor([3, 4, 4, 5, 8, 9])\n",
      "Epoch [22] -- Train\n",
      "OUT SHAPE torch.Size([32, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [22] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([5, 5, 7, 2, 3, 9, 2]) --> tensor([5, 5, 5, 5, 9, 9, 9]) --> tensor([2, 2, 3, 5, 5, 7, 9])\n",
      "tensor([5, 0, 9, 5, 6, 9, 3]) --> tensor([0, 0, 0, 0, 0, 9, 9]) --> tensor([0, 3, 5, 5, 6, 9, 9])\n",
      "tensor([5, 2, 0, 2, 0, 4, 7]) --> tensor([0, 0, 0, 0, 7, 7, 7]) --> tensor([0, 0, 2, 2, 4, 5, 7])\n",
      "tensor([4, 2, 4, 4, 9, 4, 5]) --> tensor([2, 2, 2, 2, 9, 9, 9]) --> tensor([2, 4, 4, 4, 4, 5, 9])\n",
      "Epoch [23] -- Train\n",
      "OUT SHAPE torch.Size([32, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [23] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 10, 256])\n",
      "OUTPUTS SHAPE  torch.Size([10, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([7, 6, 4, 5, 6, 6, 8, 3, 4, 8]) --> tensor([7, 3, 7, 7, 8, 8, 8, 8, 8, 8]) --> tensor([3, 4, 4, 5, 6, 6, 6, 7, 8, 8])\n",
      "tensor([1, 9, 0, 9, 8, 5, 7, 7, 6, 9]) --> tensor([1, 1, 1, 1, 0, 8, 9, 9, 9, 9]) --> tensor([0, 1, 5, 6, 7, 7, 8, 9, 9, 9])\n",
      "tensor([9, 6, 1, 1, 1, 6, 8, 2, 1, 8]) --> tensor([1, 1, 1, 1, 6, 8, 8, 8, 8, 8]) --> tensor([1, 1, 1, 1, 2, 6, 6, 8, 8, 9])\n",
      "tensor([9, 2, 6, 1, 4, 3, 9, 8, 9, 0]) --> tensor([0, 0, 0, 0, 0, 9, 9, 9, 9, 9]) --> tensor([0, 1, 2, 3, 4, 6, 8, 9, 9, 9])\n",
      "Epoch [24] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [24] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 8, 256])\n",
      "OUTPUTS SHAPE  torch.Size([8, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([8, 9, 9, 8, 8, 5, 3, 5]) --> tensor([3, 3, 8, 9, 9, 9, 9, 9]) --> tensor([3, 5, 5, 8, 8, 8, 9, 9])\n",
      "tensor([9, 1, 6, 1, 7, 9, 5, 2]) --> tensor([1, 1, 1, 1, 9, 9, 9, 9]) --> tensor([1, 1, 2, 5, 6, 7, 9, 9])\n",
      "tensor([8, 8, 3, 1, 5, 5, 9, 2]) --> tensor([1, 1, 1, 8, 9, 9, 9, 9]) --> tensor([1, 2, 3, 5, 5, 8, 8, 9])\n",
      "tensor([3, 5, 7, 3, 6, 4, 5, 7]) --> tensor([3, 3, 3, 7, 7, 7, 7, 7]) --> tensor([3, 3, 4, 5, 5, 6, 7, 7])\n",
      "Epoch [25] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [25] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 9, 256])\n",
      "OUTPUTS SHAPE  torch.Size([9, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([6, 0, 8, 2, 3, 9, 5, 2, 6]) --> tensor([0, 0, 0, 9, 9, 9, 9, 9, 9]) --> tensor([0, 2, 2, 3, 5, 6, 6, 8, 9])\n",
      "tensor([8, 9, 2, 7, 1, 6, 3, 3, 9]) --> tensor([1, 1, 1, 9, 9, 9, 9, 9, 9]) --> tensor([1, 2, 3, 3, 6, 7, 8, 9, 9])\n",
      "tensor([4, 4, 1, 6, 6, 9, 2, 6, 9]) --> tensor([2, 1, 1, 9, 9, 9, 9, 9, 9]) --> tensor([1, 2, 4, 4, 6, 6, 6, 9, 9])\n",
      "tensor([1, 7, 9, 1, 5, 9, 9, 5, 3]) --> tensor([1, 1, 1, 9, 9, 9, 9, 9, 9]) --> tensor([1, 1, 3, 5, 5, 7, 9, 9, 9])\n",
      "Epoch [26] -- Train\n",
      "OUT SHAPE torch.Size([32, 7, 256])\n",
      "OUTPUTS SHAPE  torch.Size([7, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n",
      "Epoch [26] -- Evaluate\n",
      "OUT SHAPE torch.Size([4, 9, 256])\n",
      "OUTPUTS SHAPE  torch.Size([9, 4])\n",
      "DEC IN SHAPE  torch.Size([4, 1, 1])\n",
      "tensor([2, 7, 7, 4, 2, 4, 8, 6, 4]) --> tensor([2, 2, 2, 8, 8, 8, 8, 8, 8]) --> tensor([2, 2, 4, 4, 4, 6, 7, 7, 8])\n",
      "tensor([1, 2, 5, 7, 7, 4, 7, 1, 8]) --> tensor([1, 1, 1, 8, 8, 8, 8, 8, 8]) --> tensor([1, 1, 2, 4, 5, 7, 7, 7, 8])\n",
      "tensor([6, 2, 1, 1, 4, 4, 6, 7, 3]) --> tensor([1, 1, 1, 7, 7, 7, 7, 7, 7]) --> tensor([1, 1, 2, 3, 4, 4, 6, 6, 7])\n",
      "tensor([3, 4, 6, 2, 3, 3, 6, 5, 1]) --> tensor([1, 1, 1, 6, 6, 6, 6, 6, 6]) --> tensor([1, 2, 3, 3, 3, 4, 5, 6, 6])\n",
      "Epoch [27] -- Train\n",
      "OUT SHAPE torch.Size([32, 6, 256])\n",
      "OUTPUTS SHAPE  torch.Size([6, 32])\n",
      "DEC IN SHAPE  torch.Size([32, 1, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a186f2e2496d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a186f2e2496d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, epoch, clip)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ca\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Module implementing the pointer network proposed at: https://arxiv.org/abs/1506.03134\n",
    "The implementation try to follows the variables naming conventions\n",
    "ei: Encoder hidden state\n",
    "di: Decoder hidden state\n",
    "di_prime: Attention aware decoder state\n",
    "W1: Learnable matrix (Attention layer)\n",
    "W2: Learnable matrix (Attention layer)\n",
    "V: Learnable parameter (Attention layer)\n",
    "uj: Energy vector (Attention Layer)\n",
    "aj: Attention mask over the input\n",
    "\"\"\"\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import batch\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 500\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (BATCH, ARRAY_LEN, 1)\n",
    "        return self.lstm(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = nn.Linear(hidden_size, units, bias=False)\n",
    "        self.W2 = nn.Linear(hidden_size, units, bias=False)\n",
    "        self.V =  nn.Linear(units, 1, bias=False)\n",
    "\n",
    "    def forward(self, \n",
    "                  encoder_out: torch.Tensor, \n",
    "                  decoder_hidden: torch.Tensor):\n",
    "        # encoder_out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # decoder_hidden: (BATCH, HIDDEN_SIZE)\n",
    "\n",
    "        # Add time axis to decoder hidden state\n",
    "        # in order to make operations compatible with encoder_out\n",
    "        # decoder_hidden_time: (BATCH, 1, HIDDEN_SIZE)\n",
    "        decoder_hidden_time = decoder_hidden.unsqueeze(1)\n",
    "\n",
    "        # uj: (BATCH, ARRAY_LEN, ATTENTION_UNITS)\n",
    "        # Note: we can add the both linear outputs thanks to broadcasting\n",
    "        uj = self.W1(encoder_out) + self.W2(decoder_hidden_time)\n",
    "        uj = torch.tanh(uj)\n",
    "\n",
    "        # uj: (BATCH, ARRAY_LEN, 1)\n",
    "        uj = self.V(uj)\n",
    "\n",
    "        # Attention mask over inputs\n",
    "        # aj: (BATCH, ARRAY_LEN, 1)\n",
    "        aj = F.softmax(uj, dim=1)\n",
    "\n",
    "        # di_prime: (BATCH, HIDDEN_SIZE)\n",
    "        di_prime = aj * encoder_out\n",
    "        di_prime = di_prime.sum(1)\n",
    "\n",
    "        return di_prime, uj.squeeze(-1)\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "               hidden_size: int,\n",
    "               attention_units: int = 10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(hidden_size + 1, hidden_size, batch_first=True)\n",
    "        self.attention = Attention(hidden_size, attention_units)\n",
    "\n",
    "    def forward(self, \n",
    "                  x: torch.Tensor, \n",
    "                  hidden: Tuple[torch.Tensor], \n",
    "                  encoder_out: torch.Tensor):\n",
    "        # x: (BATCH, 1, 1) \n",
    "        # hidden: (1, BATCH, HIDDEN_SIZE)\n",
    "        # encoder_out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # For a better understanding about hidden shapes read: https://pytorch.org/docs/stable/nn.html#lstm\n",
    "\n",
    "        # Get hidden states (not cell states) \n",
    "        # from the first and unique LSTM layer \n",
    "        ht = hidden[0][0]  # ht: (BATCH, HIDDEN_SIZE)\n",
    "\n",
    "        # di: Attention aware hidden state -> (BATCH, HIDDEN_SIZE)\n",
    "        # att_w: Not 'softmaxed', torch will take care of it -> (BATCH, ARRAY_LEN)\n",
    "        di, att_w = self.attention(encoder_out, ht)\n",
    "\n",
    "        # Append attention aware hidden state to our input\n",
    "        # x: (BATCH, 1, 1 + HIDDEN_SIZE)\n",
    "        x = torch.cat([di.unsqueeze(1), x], dim=2)\n",
    "\n",
    "        # Generate the hidden state for next timestep\n",
    "        _, hidden = self.lstm(x, hidden)\n",
    "        return hidden, att_w\n",
    "\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "                   encoder: nn.Module, \n",
    "                   decoder: nn.Module):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, \n",
    "                  x: torch.Tensor, \n",
    "                  y: torch.Tensor, \n",
    "                  teacher_force_ratio=.5):\n",
    "        # x: (BATCH_SIZE, ARRAY_LEN)\n",
    "        # y: (BATCH_SIZE, ARRAY_LEN)\n",
    "\n",
    "        # Array elements as features\n",
    "        # encoder_in: (BATCH, ARRAY_LEN, 1)\n",
    "        encoder_in = x.unsqueeze(-1).type(torch.float)\n",
    "        \n",
    "        # out: (BATCH, ARRAY_LEN, HIDDEN_SIZE)\n",
    "        # hs: tuple of (NUM_LAYERS, BATCH, HIDDEN_SIZE)\n",
    "        out, hs = encoder(encoder_in)\n",
    "\n",
    "        # Accum loss throughout timesteps\n",
    "        loss = 0\n",
    "\n",
    "        # Save outputs at each timestep\n",
    "        # outputs: (ARRAY_LEN, BATCH)\n",
    "        outputs = torch.zeros(out.size(1), out.size(0), dtype=torch.long)\n",
    "\n",
    "        # First decoder input is always 0\n",
    "        # dec_in: (BATCH, 1, 1)\n",
    "        dec_in = torch.zeros(out.size(0), 1, 1, dtype=torch.float)\n",
    "\n",
    "        print(\"OUT SHAPE\", out.shape)\n",
    "        print(\"OUTPUTS SHAPE \", outputs.shape)\n",
    "        print(\"DEC IN SHAPE \", dec_in.shape)\n",
    "        \n",
    "        for t in range(out.size(1)):\n",
    "            hs, att_w = decoder(dec_in, hs, out)\n",
    "            predictions = F.softmax(att_w, dim=1).argmax(1)\n",
    "\n",
    "            # Pick next index\n",
    "            # If teacher force the next element will we the ground truth\n",
    "            # otherwise will be the predicted value at current timestep\n",
    "            teacher_force = random.random() < teacher_force_ratio\n",
    "            idx = y[:, t] if teacher_force else predictions\n",
    "            dec_in = torch.stack([x[b, idx[b].item()] for b in range(x.size(0))])\n",
    "            dec_in = dec_in.view(out.size(0), 1, 1).type(torch.float)\n",
    "\n",
    "            # Add cross entropy loss (F.log_softmax + nll_loss)\n",
    "            loss += F.cross_entropy(att_w, y[:, t])\n",
    "            outputs[t] = predictions\n",
    "\n",
    "        # Weight losses, so every element in the batch \n",
    "        # has the same 'importance' \n",
    "        batch_loss = loss / y.size(0)\n",
    "\n",
    "        return outputs, batch_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, clip=1.):\n",
    "    \"\"\"Train single epoch\"\"\"\n",
    "    print('Epoch [{}] -- Train'.format(epoch))\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        x, y = batch(BATCH_SIZE)\n",
    "        out, loss = model(x, y)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        break\n",
    "\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print('Epoch [{}] loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, epoch):\n",
    "    \"\"\"Evaluate after a train epoch\"\"\"\n",
    "    print('Epoch [{}] -- Evaluate'.format(epoch))\n",
    "\n",
    "    x_val, y_val = batch(4)\n",
    "\n",
    "    out, _ = model(x_val, y_val, teacher_force_ratio=0.)\n",
    "    out = out.permute(1, 0)\n",
    "\n",
    "    for i in range(out.size(0)):\n",
    "        print('{} --> {} --> {}'.format(\n",
    "          x_val[i], \n",
    "          x_val[i].gather(0, out[i]), \n",
    "          x_val[i].gather(0, y_val[i])\n",
    "        ))\n",
    "        break\n",
    "\n",
    "\n",
    "encoder = Encoder(HIDDEN_SIZE)\n",
    "decoder = Decoder(HIDDEN_SIZE)\n",
    "ptr_net = PointerNetwork(encoder, decoder)\n",
    "\n",
    "optimizer = optim.Adam(ptr_net.parameters())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(ptr_net, optimizer, epoch + 1)\n",
    "    evaluate(ptr_net, epoch + 1)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
