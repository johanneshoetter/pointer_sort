{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Pointer Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pointer_net import PointerNet\n",
    "from utils.preprocessing import WordEmbedding, load_word_emb\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained GloVe embeddings and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GloVe word embeddings\n",
    "w2v_config = {\n",
    "    'data_dir': 'data/glove',\n",
    "    'word2idx_path': 'word2idx.json',\n",
    "    'usedwordemb_path': 'usedwordemb.npy'\n",
    "}\n",
    "w2v = WordEmbedding(load_word_emb(w2v_config['data_dir'], \n",
    "                                          w2v_config['word2idx_path'],\n",
    "                                          w2v_config['usedwordemb_path'])\n",
    "                           )\n",
    "\n",
    "# Network architecture\n",
    "model_params = {\n",
    "    'input_size': 300,\n",
    "    'embedding_size': 300,\n",
    "    'hiddens': 256,\n",
    "    'nof_lstms': 2,\n",
    "    'dropout': 0,\n",
    "    'bidir': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Pointer definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \n",
    "x = \\texttt{<BEG>} \\cdot x^{s} \\cdot \\texttt{<SEP>} \\cdot x^{t}_{1} \\cdot x^{t}_2 \\cdot ...x^{t}_{N} \\cdot \\texttt{<END>}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaPointer1D():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w2v = None\n",
    "        self.model = None\n",
    "        \n",
    "    def __call__(self, source_col, target_schema, verbose=False):\n",
    "        features, sequence_tok = self._preprocess(source_col, target_schema)\n",
    "        _, pointers = self.model(features)\n",
    "        try:\n",
    "            prediction = sequence_tok[pointers[0][:pointers[0].argmax()]] # pointer until end token\n",
    "        except:\n",
    "            prediction = '<NONE>'\n",
    "        if verbose:\n",
    "            print(\"x = {}\".format(';'.join(sequence_tok)))\n",
    "            print(\"y = {}\".format(prediction))\n",
    "        return prediction\n",
    "        \n",
    "    def set_w2v(self, w2v):\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def initialize(self, params, path='serialized/schema_pointer_sp.pt'):\n",
    "        self.model = PointerNet(params['input_size'],\n",
    "                   params['embedding_size'],\n",
    "                   params['hiddens'],\n",
    "                   params['nof_lstms'],\n",
    "                   params['dropout'],\n",
    "                   params['bidir'])\n",
    "        self.model.initialize(path)\n",
    "        self.model.eval() # inference phase       \n",
    "    \n",
    "    def _preprocess(self, source_col, target_schema):\n",
    "        source_col = source_col.lower()\n",
    "        target_schema = ';'.join(target_schema).lower()\n",
    "        input_sequence = \"<BEG>;{};<SEQ>;{};<END>\".format(source_col, target_schema)\n",
    "        embeddings = []\n",
    "        input_sequence_tok = input_sequence.split(';')\n",
    "        for token in input_sequence_tok:\n",
    "            embedding = np.mean([w2v(word) for word in token], axis=0)\n",
    "            embeddings.append(embedding)\n",
    "        embeddings = torch.Tensor(embeddings)\n",
    "        features = embeddings.unsqueeze(0)\n",
    "        return features, input_sequence_tok\n",
    "    \n",
    "schema_pointer = SchemaPointer1D()\n",
    "schema_pointer.set_w2v(w2v)\n",
    "schema_pointer.initialize(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = <BEG>;ca team;<SEQ>;date;site;sport;winning team;series;<END>\n",
      "y = date\n",
      "----------------------------------------------------------------------------------------------------\n",
      "x = <BEG>;ice;<SEQ>;102;28 february;friendly;croatia;austria;<END>\n",
      "y = <NONE>\n"
     ]
    }
   ],
   "source": [
    "# example: \n",
    "# source_col,input_cols,target_cols\n",
    "# CA Winning Team,Date<|>Site<|>Sport<|>Winning team<|>Series,Winning team\n",
    "source_col = 'CA Winning Team'\n",
    "target_schema = ['Date', 'Site', 'Sport', 'Winning team', 'Series']\n",
    "match = schema_pointer(source_col, target_schema, verbose=True)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "# Sundsvall,102.<|>28 February<|>Friendly<|>Croatia<|>Austria,\n",
    "source_col = 'ice'\n",
    "target_schema = ['102', '28 February', 'Friendly', 'Croatia', 'Austria']\n",
    "match = schema_pointer(source_col, target_schema, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
